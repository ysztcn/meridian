{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U openai json-repair google-genai gliclass rapidfuzz \"transformers>=4.48.0\" retry ipywidgets widgetsnbextension pandas-profiling readtime optuna bertopic supabase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from src.events import get_events\n",
        "\n",
        "sources, events = get_events()\n",
        "print(f\"Number of events: {len(events)}\")\n",
        "print(f\"Number of sources: {len(sources)}\")\n",
        "\n",
        "articles_df = pd.DataFrame(events)\n",
        "# clean up those tuples\n",
        "for col in articles_df.columns:\n",
        "    articles_df[col] = articles_df[col].apply(\n",
        "        lambda x: x[1] if isinstance(x, tuple) else x\n",
        "    )\n",
        "articles_df.columns = [\n",
        "    \"id\",\n",
        "    \"sourceId\",\n",
        "    \"url\",\n",
        "    \"title\",\n",
        "    \"publishDate\",\n",
        "    \"content\",\n",
        "    \"location\",\n",
        "    \"relevance\",\n",
        "    \"completeness\",\n",
        "    \"summary\",\n",
        "]\n",
        "articles_df[\"summary\"] = (\n",
        "    articles_df[\"summary\"]\n",
        "    .str.split(\"EVENT:\")\n",
        "    .str[1]\n",
        "    .str.split(\"CONTEXT:\")\n",
        "    .str[0]\n",
        "    .str.strip()\n",
        ")\n",
        "articles_df[\"text_to_embed\"] = \"query: \" + articles_df[\"summary\"]\n",
        "articles_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prep: embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# helper function for pooling (straight from the docs)\n",
        "def average_pool(last_hidden_states, attention_mask):\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "# load the multilingual model\n",
        "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-small')\n",
        "model = AutoModel.from_pretrained('intfloat/multilingual-e5-small')\n",
        "\n",
        "\n",
        "# batch processing to avoid memory issues\n",
        "batch_size = 64\n",
        "all_embeddings = []\n",
        "\n",
        "# process in batches with progress bar\n",
        "for i in tqdm(range(0, len(articles_df), batch_size)):\n",
        "    batch_texts = articles_df['text_to_embed'].iloc[i:i+batch_size].tolist()\n",
        "    \n",
        "    # tokenize\n",
        "    batch_dict = tokenizer(batch_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    \n",
        "    # generate embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "    \n",
        "    # pool and normalize\n",
        "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "    \n",
        "    # convert to numpy and add to list\n",
        "    all_embeddings.extend(embeddings.numpy())\n",
        "\n",
        "# store in dataframe\n",
        "articles_df['embedding'] = all_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid search umap & hdbscan params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import hdbscan\n",
        "import umap\n",
        "from hdbscan.validity import validity_index\n",
        "\n",
        "\n",
        "def optimize_clusters(embeddings, umap_params, hdbscan_params):\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    # grid search both umap and hdbscan params\n",
        "    for n_neighbors in umap_params[\"n_neighbors\"]:\n",
        "        # fit umap once per n_neighbors config\n",
        "        reducer = umap.UMAP(\n",
        "            n_neighbors=n_neighbors,\n",
        "            n_components=10,\n",
        "            min_dist=0.0,\n",
        "            metric=\"cosine\",\n",
        "            random_state=42,\n",
        "        )\n",
        "        reduced_data = reducer.fit_transform(embeddings)\n",
        "\n",
        "        for min_cluster_size in hdbscan_params[\"min_cluster_size\"]:\n",
        "            for min_samples in hdbscan_params[\"min_samples\"]:\n",
        "                for epsilon in hdbscan_params[\"epsilon\"]:\n",
        "                    # cluster with hdbscan\n",
        "                    clusterer = hdbscan.HDBSCAN(\n",
        "                        min_cluster_size=min_cluster_size,\n",
        "                        min_samples=min_samples,\n",
        "                        cluster_selection_epsilon=epsilon,\n",
        "                        metric=\"euclidean\",\n",
        "                        prediction_data=True,\n",
        "                    )\n",
        "\n",
        "                    cluster_labels = clusterer.fit_predict(reduced_data)\n",
        "\n",
        "                    # skip if all noise\n",
        "                    if np.all(cluster_labels == -1):\n",
        "                        continue\n",
        "\n",
        "                    # evaluate with dbcv (better for density clusters)\n",
        "                    valid_points = cluster_labels != -1\n",
        "                    if (\n",
        "                        valid_points.sum() > 1\n",
        "                        and len(set(cluster_labels[valid_points])) > 1\n",
        "                    ):\n",
        "                        try:\n",
        "                            reduced_data_64 = reduced_data[valid_points].astype(\n",
        "                                np.float64\n",
        "                            )\n",
        "                            score = validity_index(\n",
        "                                reduced_data_64, cluster_labels[valid_points]\n",
        "                            )\n",
        "\n",
        "                            if score > best_score:\n",
        "                                best_score = score\n",
        "                                best_params = {\n",
        "                                    \"umap\": {\"n_neighbors\": n_neighbors},\n",
        "                                    \"hdbscan\": {\n",
        "                                        \"min_cluster_size\": min_cluster_size,\n",
        "                                        \"min_samples\": min_samples,\n",
        "                                        \"epsilon\": epsilon,\n",
        "                                    },\n",
        "                                }\n",
        "                                print(f\"new best: {best_score:.4f} with {best_params}\")\n",
        "                        except Exception as e:\n",
        "                            # sometimes dbcv can fail on weird cluster shapes\n",
        "                            print(f\"failed with {e}\")\n",
        "                            continue\n",
        "\n",
        "    return best_params, best_score\n",
        "\n",
        "\n",
        "# param grids - adjust ranges based on your data\n",
        "umap_params = {\"n_neighbors\": [10, 15, 20, 30]}\n",
        "\n",
        "hdbscan_params = {\n",
        "    \"min_cluster_size\": [5, 8, 10, 15],\n",
        "    \"min_samples\": [2, 3, 5],\n",
        "    \"epsilon\": [0.1, 0.2, 0.3],\n",
        "}\n",
        "\n",
        "# assuming embeddings is your data\n",
        "best_params, best_score = optimize_clusters(all_embeddings, umap_params, hdbscan_params)\n",
        "print(f\"best overall: {best_score:.4f} with {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# use the optimized params\n",
        "umap_embeddings = umap.UMAP(\n",
        "    n_neighbors=best_params[\"umap\"][\"n_neighbors\"],\n",
        "    n_components=10,  # bumped up from 5\n",
        "    min_dist=0.0,\n",
        "    metric=\"cosine\",\n",
        ").fit_transform(all_embeddings)\n",
        "\n",
        "# cluster with optimal params\n",
        "clusterer = hdbscan.HDBSCAN(\n",
        "    min_cluster_size=best_params[\"hdbscan\"][\"min_cluster_size\"],\n",
        "    min_samples=best_params[\"hdbscan\"][\"min_samples\"],\n",
        "    cluster_selection_epsilon=best_params[\"hdbscan\"][\"epsilon\"],\n",
        "    metric=\"euclidean\",\n",
        "    prediction_data=True,\n",
        ")\n",
        "cluster_labels = clusterer.fit_predict(umap_embeddings)\n",
        "\n",
        "# add to dataframe same as before\n",
        "articles_df[\"cluster\"] = cluster_labels\n",
        "\n",
        "# quick stats\n",
        "print(f\"found {len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)} clusters\")\n",
        "print(f\"noise points: {sum(cluster_labels == -1)}\")\n",
        "\n",
        "# 2d projection for visualization\n",
        "umap_2d = umap.UMAP(n_components=2, metric=\"cosine\").fit_transform(all_embeddings)\n",
        "\n",
        "# plotting\n",
        "plt.figure(figsize=(12, 10))\n",
        "# plot noise points first (gray)\n",
        "plt.scatter(\n",
        "    umap_2d[cluster_labels == -1, 0],\n",
        "    umap_2d[cluster_labels == -1, 1],\n",
        "    c=\"lightgray\",\n",
        "    s=5,\n",
        "    alpha=0.5,\n",
        "    label=\"noise\",\n",
        ")\n",
        "\n",
        "# plot actual clusters with random colors\n",
        "unique_clusters = sorted(list(set(cluster_labels) - {-1}))\n",
        "palette = sns.color_palette(\"husl\", len(unique_clusters))\n",
        "\n",
        "for i, cluster_id in enumerate(unique_clusters):\n",
        "    plt.scatter(\n",
        "        umap_2d[cluster_labels == cluster_id, 0],\n",
        "        umap_2d[cluster_labels == cluster_id, 1],\n",
        "        c=[palette[i]],\n",
        "        s=25,\n",
        "        label=f\"cluster {cluster_id}\",\n",
        "    )\n",
        "\n",
        "plt.title(\"article clusters\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Cluster review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clusters_ids = list(set(cluster_labels) - {-1})\n",
        "clusters_with_articles = []\n",
        "for cluster_id in clusters_ids:\n",
        "    cluster_df = articles_df[articles_df['cluster'] == cluster_id]\n",
        "    articles_ids = cluster_df['id'].tolist()\n",
        "    clusters_with_articles.append({\n",
        "        \"cluster_id\": cluster_id,\n",
        "        \"articles_ids\": articles_ids\n",
        "    })\n",
        "# sort clusters by most articles to least articles\n",
        "clusters_with_articles = sorted(clusters_with_articles, key=lambda x: len(x['articles_ids']), reverse=True)\n",
        "print(len(clusters_with_articles))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "from google.genai import types\n",
        "from retry import retry\n",
        "import json\n",
        "from json_repair import repair_json\n",
        "from pydantic import BaseModel, Field, model_validator\n",
        "from typing import List, Literal, Optional\n",
        "from src.llm import call_llm\n",
        "\n",
        "\n",
        "class Story(BaseModel):\n",
        "    title: str = Field(description=\"title of the story\")\n",
        "    importance: int = Field(\n",
        "        ge=1,\n",
        "        le=10,\n",
        "        description=\"global significance (1=minor local event, 10=major global impact)\",\n",
        "    )\n",
        "    articles: List[int] = Field(description=\"list of article ids in the story\")\n",
        "\n",
        "\n",
        "class StoryValidation(BaseModel):\n",
        "    answer: Literal[\"single_story\", \"collection_of_stories\", \"pure_noise\", \"no_stories\"]\n",
        "\n",
        "    # optional fields that depend on the answer type\n",
        "    title: Optional[str] = None\n",
        "    importance: Optional[int] = Field(None, ge=1, le=10)\n",
        "    outliers: List[int] = Field(default_factory=list)\n",
        "    stories: Optional[List[Story]] = None\n",
        "\n",
        "    @model_validator(mode=\"after\")\n",
        "    def validate_structure(self):\n",
        "        if self.answer == \"single_story\":\n",
        "            if self.title is None or self.importance is None:\n",
        "                raise ValueError(\n",
        "                    \"'title' and 'importance' are required for 'single_story'\"\n",
        "                )\n",
        "            if self.stories is not None:\n",
        "                raise ValueError(\"'stories' should not be present for 'single_story'\")\n",
        "\n",
        "        elif self.answer == \"collection_of_stories\":\n",
        "            if not self.stories:\n",
        "                raise ValueError(\"'stories' is required for 'collection_of_stories'\")\n",
        "            if self.title is not None or self.importance is not None or self.outliers:\n",
        "                raise ValueError(\n",
        "                    \"'title', 'importance', and 'outliers' should not be present for 'collection_of_stories'\"\n",
        "                )\n",
        "\n",
        "        elif self.answer == \"pure_noise\" or self.answer == \"no_stories\":\n",
        "            if (\n",
        "                self.title is not None\n",
        "                or self.importance is not None\n",
        "                or self.outliers\n",
        "                or self.stories is not None\n",
        "            ):\n",
        "                raise ValueError(\n",
        "                    \"no additional fields should be present for 'pure_noise'\"\n",
        "                )\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "@retry(tries=3, delay=2, backoff=2, jitter=2, max_delay=20)\n",
        "def process_story(cluster):\n",
        "\n",
        "    story_articles_ids = cluster[\"articles_ids\"]\n",
        "\n",
        "    story_article_md = \"\"\n",
        "    for article_id in story_articles_ids:\n",
        "        article = next((e for e in events if e.id == article_id), None)\n",
        "        if article is None:\n",
        "            continue\n",
        "        story_article_md += f\"- (#{article.id}) [{article.title}]({article.url})\\n\"\n",
        "        # story_article_md += f\"> {article.publishDate}\\n\\n\"\n",
        "        # story_article_md += f\"```\\n{article.content}\\n```\\n\\n\"\n",
        "    story_article_md = story_article_md.strip()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "# Task\n",
        "Determine if the following collection of news articles is:\n",
        "1) A single story - A cohesive narrative where all articles relate to the same central event/situation and its direct consequences\n",
        "2) A collection of stories - Distinct narratives that should be analyzed separately\n",
        "3) Pure noise - Random articles with no meaningful pattern\n",
        "4) No stories - Distinct narratives but none of them have more than 3 articles\n",
        "\n",
        "# Important clarification\n",
        "A \"single story\" can still have multiple aspects or angles. What matters is whether the articles collectively tell one broader narrative where understanding each part enhances understanding of the whole.\n",
        "\n",
        "# Handling outliers\n",
        "- For single stories: You can exclude true outliers in an \"outliers\" array\n",
        "- For collections: Focus **only** on substantive stories (3+ articles). Ignore one-off articles or noise.\n",
        "\n",
        "# Title guidelines\n",
        "- Titles should be purely factual, descriptive and neutral\n",
        "- Include necessary context (region, countries, institutions involved)\n",
        "- No editorialization, opinion, or emotional language\n",
        "- Format: \"[Subject] [action/event] in/with [location/context]\"\n",
        "\n",
        "# Input data\n",
        "Articles (format is (#id) [title](url)):\n",
        "{story_article_md}\n",
        "\n",
        "# Output format\n",
        "Start by reasoning step by step. Consider:\n",
        "- Central themes and events\n",
        "- Temporal relationships (are events happening in the same timeframe?)\n",
        "- Causal relationships (do events influence each other?)\n",
        "- Whether splitting the narrative would lose important context\n",
        "\n",
        "Return your final answer in JSON format:\n",
        "```json\n",
        "{{\n",
        "    \"answer\": \"single_story\" | \"collection_of_stories\" | \"pure_noise\",\n",
        "    // single_story_start: if answer is \"single_story\", include the following fields:\n",
        "    \"title\": \"title of the story\",\n",
        "    \"importance\": 1-10, // global significance (1=minor local event, 10=major global impact)\n",
        "    \"outliers\": [] // array of article ids to exclude as unrelated\n",
        "    // single_story_end\n",
        "    // collection_of_stories_start: if answer is \"collection_of_stories\", include the following fields:\n",
        "    \"stories\": [\n",
        "        {{\n",
        "            \"title\": \"title of the story\",\n",
        "            \"importance\": 1-10, // global significance scale\n",
        "            \"articles\": [] // list of article ids in the story (**only** include substantial stories with **3+ articles**)\n",
        "        }},\n",
        "        ...\n",
        "    ]\n",
        "    // collection_of_stories_end\n",
        "}}\n",
        "```\n",
        "\n",
        "Example for a single story:\n",
        "```json\n",
        "{{\n",
        "    \"answer\": \"single_story\",\n",
        "    \"title\": \"The Great Fire of London\",\n",
        "    \"importance\": 8,\n",
        "    \"outliers\": [123, 456] // article ids to exclude as unrelated\n",
        "}}\n",
        "```\n",
        "\n",
        "Example for a collection of stories:\n",
        "```json\n",
        "{{\n",
        "    \"answer\": \"collection_of_stories\",\n",
        "    \"stories\": [\n",
        "        {{\n",
        "            \"title\": \"The Great Fire of London\",\n",
        "            \"importance\": 8,\n",
        "            \"articles\": [123, 456] // article ids in the story\n",
        "        }},\n",
        "        ...\n",
        "    ]\n",
        "}}\n",
        "```\n",
        "\n",
        "Example for pure noise:\n",
        "```json\n",
        "{{\n",
        "    \"answer\": \"pure_noise\"\n",
        "}}\n",
        "```\n",
        "\n",
        "Example for a distinct narratives with no stories that contain more than 3+ articles:\n",
        "```json\n",
        "{{\n",
        "    \"answer\": \"no_stories\",\n",
        "}}\n",
        "```\n",
        "\n",
        "Note:\n",
        "- Always include articles IDs (outliers, articles, etc...) as integers, not strings and never include the # symbol.\n",
        "\"\"\".strip()\n",
        "\n",
        "    answer, usage = call_llm(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        assert \"```json\" in answer\n",
        "        answer = answer.split(\"```json\")[1]\n",
        "        if answer.endswith(\"```\"):\n",
        "            answer = answer[:-3]\n",
        "        answer = answer.strip()\n",
        "        answer = repair_json(answer)\n",
        "        answer = json.loads(answer)\n",
        "        parsed = StoryValidation(**answer)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing story: {e}\")\n",
        "        print(cluster)\n",
        "        print(answer)\n",
        "        raise e\n",
        "\n",
        "    return (parsed, usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Submit all tasks and process in parallel\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Submit all tasks and get future objects\n",
        "    futures = [\n",
        "        executor.submit(process_story, story) for story in clusters_with_articles\n",
        "    ]\n",
        "\n",
        "    # Use tqdm to show progress while getting results\n",
        "    cleaned_clusters_raw = list(\n",
        "        tqdm(\n",
        "            (future.result() for future in futures),\n",
        "            total=len(futures),\n",
        "            desc=\"Processing stories\",\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleaned_clusters = []\n",
        "for i in range(len(clusters_with_articles)):\n",
        "    base = clusters_with_articles[i]\n",
        "    res = cleaned_clusters_raw[i][0]\n",
        "\n",
        "    if res.answer == \"single_story\":\n",
        "        \n",
        "        article_ids = base[\"articles_ids\"]\n",
        "        # filter out outliers\n",
        "        article_ids = [x for x in article_ids if x not in res.outliers]\n",
        "        \n",
        "        cleaned_clusters.append(\n",
        "            Story(\n",
        "                title=res.title,\n",
        "                importance=res.importance,\n",
        "                articles=article_ids,\n",
        "            )\n",
        "        )\n",
        "    elif res.answer == \"collection_of_stories\":\n",
        "        for story in res.stories:\n",
        "            cleaned_clusters.append(story)\n",
        "\n",
        "# sort by importance\n",
        "cleaned_clusters = sorted(cleaned_clusters, key=lambda x: x.importance, reverse=True)\n",
        "\n",
        "lowest_importance = cleaned_clusters[0].importance\n",
        "highest_importance = cleaned_clusters[-1].importance\n",
        "\n",
        "print(f\"lowest importance: {lowest_importance}\")\n",
        "print(f\"highest importance: {highest_importance}\")\n",
        "\n",
        "print(len(cleaned_clusters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot distribution of importance\n",
        "importance_values = [cluster.importance for cluster in cleaned_clusters]\n",
        "plt.hist(importance_values, bins=20, edgecolor='black')\n",
        "plt.title('Distribution of Importance Scores')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# show clusters with importance < 5\n",
        "low_importance_clusters = [cluster for cluster in cleaned_clusters if cluster.importance < 5]\n",
        "high_importance_clusters = [cluster for cluster in cleaned_clusters if cluster.importance >= 5]\n",
        "print(len(low_importance_clusters))\n",
        "print(len(high_importance_clusters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in cleaned_clusters:\n",
        "    print(f\"# {x.title}\")\n",
        "    for article_id in x.articles:\n",
        "        article = article = next((e for e in events if e.id == article_id), None)\n",
        "        if article is not None:\n",
        "            print(f\"  - {article.title}\")\n",
        "        else:\n",
        "            print(f\" MISSED article_id: {article_id}\")\n",
        "            # print(f\"- {article.title}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LLM Analyze & enrich cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import tiktoken\n",
        "\n",
        "enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "\n",
        "\n",
        "@retry(\n",
        "    tries=4, delay=2, backoff=2, jitter=1, max_delay=20\n",
        ")  # max_delay=180 means never wait more than 3 mins\n",
        "def final_process_story(title: str, articles_ids: list[int]):\n",
        "\n",
        "    story_article_md = \"\"\n",
        "    full_articles = []\n",
        "    for article_id in articles_ids:\n",
        "        article = next((e for e in events if e.id == article_id), None)\n",
        "        if article is None:\n",
        "            print(f\"Article {article_id} not found\")\n",
        "            continue\n",
        "        else:\n",
        "            full_articles.append(article)\n",
        "\n",
        "    # sort by publish date (from latest to oldest)\n",
        "    # full_articles = sorted(full_articles, key=lambda x: x[\"publishDate\"], reverse=True)\n",
        "    for article in full_articles:\n",
        "        story_article_md += f\"## [{article.title}]({article.url}) (#{article.id})\\n\\n\"\n",
        "        story_article_md += f\"> {article.publishDate}\\n\\n\"\n",
        "        story_article_md += f\"```\\n{article.content}\\n```\\n\\n\"\n",
        "\n",
        "    story_article_md = story_article_md.strip()\n",
        "\n",
        "    pre_prompt = \"\"\"\n",
        "You are a highly skilled intelligence analyst working for a prestigious agency. Your task is to analyze a cluster of related news articles and extract structured information for an executive intelligence report. The quality, accuracy, precision, and **consistency** of your analysis are crucial, as this report will directly inform a high-level daily brief and potentially decision-making.\n",
        "\n",
        "First, assess if the articles provided contain sufficient content for analysis:\n",
        "\n",
        "Here is the cluster of related news articles you need to analyze:\n",
        "\n",
        "<articles>\n",
        "\"\"\".strip()\n",
        "\n",
        "    post_prompt = \"\"\"\n",
        "</articles>\n",
        "\n",
        "BEGIN ARTICLE QUALITY CHECK:\n",
        "Before proceeding with analysis, verify if the articles contain sufficient information:\n",
        "1. Check if articles appear empty or contain minimal text (fewer than ~50 words each)\n",
        "2. Check for paywall indicators (\"subscribe to continue\", \"premium content\", etc.)\n",
        "3. Check if articles only contain headlines/URLs but no actual content\n",
        "4. Check if articles appear truncated or cut off mid-sentence\n",
        "\n",
        "If ANY of these conditions are true, return ONLY this JSON structure inside <final_json> tags:\n",
        "<final_json>\n",
        "{\n",
        "    \"status\": \"incomplete\",\n",
        "    \"reason\": \"Brief explanation of why analysis couldn't be completed (empty articles, paywalled content, etc.)\",\n",
        "    \"availableInfo\": \"Brief summary of any information that was available\"\n",
        "}\n",
        "</final_json>\n",
        "\n",
        "ONLY IF the articles contain sufficient information for analysis, proceed with the full analysis below:\n",
        "\n",
        "Your goal is to extract and synthesize information from these articles into a structured format suitable for generating a daily intelligence brief.\n",
        "\n",
        "Before addressing the main categories, conduct a preliminary analysis:\n",
        "a) List key themes across all articles\n",
        "b) Note any recurring names, places, or events\n",
        "c) Identify potential biases or conflicting information\n",
        "It's okay for this section to be quite long as it helps structure your thinking.\n",
        "\n",
        "Then, after your preliminary analysis, present your final analysis in a structured JSON format inside <final_json> tags. This must be valid, parseable JSON that follows this **exact refined structure**:\n",
        "\n",
        "**Detailed Instructions for JSON Fields:**\n",
        "\n",
        "*   **`executiveSummary`**: Provide a 2-4 sentence concise summary highlighting the most critical developments, key conflicts, and overall assessment from the articles. This should be suitable for a quick read in a daily brief.\n",
        "*   **`storyStatus`**: Assess the current state of the story's development based *only* on the information in the articles. Use one of: 'Developing', 'Escalating', 'De-escalating', 'Concluding', 'Static'.\n",
        "*   **`timeline`**: List key events in chronological order.\n",
        "    *   `description`: Keep descriptions brief and factual.\n",
        "    *   `importance`: Assess the event's importance to understanding the overall narrative (High/Medium/Low). High importance implies the event is central to the story's development or outcome.\n",
        "*   **`signalStrength`**: Assess the overall reliability of the reporting *in this cluster*.\n",
        "    *   `assessment`: Use a qualitative term: 'Very High', 'High', 'Moderate', 'Low', 'Very Low'.\n",
        "    *   `reasoning`: Justify the assessment based on source corroboration (how many sources report the same core facts?), source quality/reliability (mix of reputable vs. biased sources?), presence of official statements, and degree of conflicting information on core facts.\n",
        "*   **`undisputedKeyFacts`**: List core factual points that are corroborated across multiple, generally reliable sources within the cluster. Avoid claims made only by highly biased sources unless corroborated.\n",
        "*   **`keyEntities`**: Identify the main actors.\n",
        "    *   `list`: Provide basic identification and their role/involvement.\n",
        "    *   `perspectives.statedPositions`: Focus *only* on the goals, viewpoints, or justifications explicitly stated or clearly implied by the entity *as reported in the articles*. Avoid listing conflicting claims here (that goes in `contradictions`).\n",
        "*   **`keySources`**: Analyze the provided news sources.\n",
        "    *   `provided_articles_sources.reliabilityAssessment`: Assess the source's general reliability based on reputation, known biases (political, state affiliation, ideological), and fact-checking standards. Use terms like 'High Reliability', 'Moderate Reliability', 'Low Reliability', 'State-Affiliated/Propaganda Outlet'. Be specific about the *type* of bias.\n",
        "    *   `provided_articles_sources.framing`: Describe the narrative angle or style used by the source (e.g., 'Emphasizes security threat', 'Focuses on human rights angle', 'Uses neutral language', 'Uses loaded/emotional language', 'Presents government narrative uncritically').\n",
        "    *   `contradictions`: Detail specific points of disagreement *between sources* or *between entities as reported by sources*.\n",
        "        *   `issue`: Clearly state what is being contested.\n",
        "        *   `conflictingClaims`: List the different versions, specifying the `source` reporting it, the `claim` itself, and optionally the `entityClaimed` if the source attributes the claim to a specific entity. Critically evaluate claims originating solely from low-reliability/propaganda sources.\n",
        "*   **`context`**: List essential background information *mentioned or clearly implied in the articles* needed to understand the story.\n",
        "*   **`informationGaps`**: Identify crucial pieces of information *missing* from the articles that would be needed for a complete understanding.\n",
        "*   **`significance`**: Assess the overall importance of the reported events.\n",
        "    *   `assessment`: Use a qualitative term: 'Critical', 'High', 'Moderate', 'Low'.\n",
        "    *   `reasoning`: Explain *why* this story matters. Consider immediate impact, potential future developments, strategic implications, precedent setting, regional/global relevance.\n",
        "\n",
        "**Refined JSON Structure to Follow:**\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"status\": \"complete\",\n",
        "    \"executiveSummary\": \"string\",\n",
        "    \"storyStatus\": \"string\",\n",
        "    \"timeline\": [\n",
        "        {\n",
        "            \"date\": \"YYYY-MM-DD or approximate\",\n",
        "            \"description\": \"brief event description\",\n",
        "            \"importance\": \"string: High/Medium/Low\"\n",
        "        }\n",
        "    ],\n",
        "    \"signalStrength\": {\n",
        "        \"assessment\": \"string: Very High/High/Moderate/Low/Very Low\",\n",
        "        \"reasoning\": \"string\"\n",
        "    },\n",
        "    \"undisputedKeyFacts\": [\n",
        "        \"string\"\n",
        "    ],\n",
        "    \"keyEntities\": {\n",
        "        \"list\": [\n",
        "            {\n",
        "                \"name\": \"entity name\",\n",
        "                \"type\": \"type of entity\",\n",
        "                \"description\": \"brief description\",\n",
        "                \"involvement\": \"why/how involved?\"\n",
        "            }\n",
        "        ],\n",
        "        \"perspectives\": [\n",
        "            {\n",
        "                \"entity\": \"entity name\",\n",
        "                \"statedPositions\": [\n",
        "                    \"string\"\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"keySources\": {\n",
        "        \"provided_articles_sources\": [\n",
        "            {\n",
        "                \"name\": \"source entity name\",\n",
        "                \"articles\": [], // int array of IDs\n",
        "                \"reliabilityAssessment\": \"string\",\n",
        "                \"framing\": [\n",
        "                    \"string\"\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"contradictions\": [\n",
        "            {\n",
        "                \"issue\": \"string\",\n",
        "                \"conflictingClaims\": [\n",
        "                    {\n",
        "                        \"source\": \"media source name\",\n",
        "                        \"entityClaimed\": \"entity name (optional)\",\n",
        "                        \"claim\": \"string\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"context\": [\n",
        "        \"string\"\n",
        "    ],\n",
        "    \"informationGaps\": [\n",
        "        \"string\"\n",
        "    ],\n",
        "    \"significance\": {\n",
        "        \"assessment\": \"string: Critical/High/Moderate/Low\",\n",
        "        \"reasoning\": \"string\"\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "**CRITICAL Quality & Consistency Requirements:**\n",
        "\n",
        "*   **Thoroughness:** Ensure all fields, especially descriptions, reasoning, context, and summaries, are detailed and specific. Avoid superficial or overly brief entries. Your analysis must reflect deep engagement with the provided texts.\n",
        "*   **Grounding:** Base your entire analysis **SOLELY** on the content within the provided `<articles>` tags. Do not introduce outside information, assumptions, or knowledge.\n",
        "*   **No Brevity Over Clarity:** Do **NOT** provide one-sentence descriptions or reasoning where detailed analysis is required by the field definition.\n",
        "*   **Scrutinize Sources:** Pay close attention to the reliability assessment of sources when evaluating claims, especially in the `contradictions` section. Note when a claim originates primarily or solely from a low-reliability source.\n",
        "*   **Validity:** Your JSON inside `<final_json></final_json>` tags MUST be 100% fully valid with no trailing commas, properly quoted strings and escaped characters where needed, and follow the exact refined structure provided. Ensure keys are in the specified order. Your entire JSON output should be directly extractable and parseable without human intervention.\n",
        "\n",
        "Return your complete response, including your preliminary analysis/thinking in any format you prefer, followed by the **full** valid JSON inside `<final_json></final_json>` tags.\n",
        "\"\"\".strip()\n",
        "\n",
        "    # enc.decode(enc.encode(\"hello world\"))\n",
        "    tokens = enc.encode(story_article_md)\n",
        "\n",
        "    # only keep the first million tokens\n",
        "    tokens = tokens[:850_000]\n",
        "    story_article_md = enc.decode(tokens)\n",
        "\n",
        "    prompt = pre_prompt + \"\\n\\n\" + story_article_md + \"\\n\\n\" + post_prompt\n",
        "    # print(prompt)\n",
        "\n",
        "    answer, usage = call_llm(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    text = answer\n",
        "\n",
        "    if \"```json\" in text:\n",
        "        text = text.split(\"```json\")[1]\n",
        "        text = text.strip()\n",
        "\n",
        "    if \"<final_json>\" in text:\n",
        "        text = text.split(\"<final_json>\")[1]\n",
        "        text = text.strip()\n",
        "\n",
        "    if \"</final_json>\" in text:\n",
        "        text = text.split(\"</final_json>\")[0]\n",
        "        text = text.strip()\n",
        "\n",
        "    if text.endswith(\"```\"):\n",
        "        text = text.replace(\"```\", \"\")\n",
        "        text = text.strip()\n",
        "\n",
        "    # text = repair_json(text)\n",
        "\n",
        "    # assert \"significance\" in text\n",
        "\n",
        "    return answer, usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "cluster_analysis = []\n",
        "\n",
        "# helper function to process a single cluster\n",
        "def process_cluster(cluster):\n",
        "    title = cluster.title\n",
        "    articles_ids = cluster.articles\n",
        "    return final_process_story(title=title, articles_ids=articles_ids)\n",
        "\n",
        "# process clusters in parallel using a thread pool\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # submit all tasks and store futures\n",
        "    futures = [executor.submit(process_cluster, cluster) \n",
        "              for cluster in cleaned_clusters]\n",
        "    \n",
        "    # collect results as they complete using tqdm for progress\n",
        "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "        cluster_analysis.append(future.result())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from json_repair import repair_json\n",
        "\n",
        "final_json_to_process = []\n",
        "\n",
        "for i in range(len(cluster_analysis)):\n",
        "    cluster = cluster_analysis[i]\n",
        "    text = cluster[0]\n",
        "\n",
        "    if \"```json\" in text:\n",
        "        text = text.split(\"```json\")[1]\n",
        "        text = text.strip()\n",
        "\n",
        "    if \"<final_json>\" in text:\n",
        "        text = text.split(\"<final_json>\")[1]\n",
        "        text = text.strip()\n",
        "\n",
        "    if \"</final_json>\" in text:\n",
        "        text = text.split(\"</final_json>\")[0]\n",
        "        text = text.strip()\n",
        "\n",
        "    if text.endswith(\"```\"):\n",
        "        text = text.replace(\"```\", \"\")\n",
        "        text = text.strip()\n",
        "\n",
        "    text = repair_json(text)\n",
        "\n",
        "    try:\n",
        "        text_parsed = json.loads(text)\n",
        "\n",
        "        if text_parsed[\"status\"] == \"incomplete\":\n",
        "            continue\n",
        "        else:\n",
        "            final_json_to_process.append(text_parsed)\n",
        "    except:\n",
        "        print(text)\n",
        "        raise Exception(\"no final json\")\n",
        "    \n",
        "# \"assessment\": \"string: Critical/High/Moderate/Low\",\n",
        "# sort assessment by \"Critical\" first, then \"High\", then \"Moderate\", then \"Low\"\n",
        "\n",
        "final_json_to_process = sorted(\n",
        "    final_json_to_process, key=lambda x: x[\"significance\"][\"assessment\"], reverse=True\n",
        ")\n",
        "\n",
        "# final_json_to_process = sorted(\n",
        "#     final_json_to_process, key=lambda x: x[\"significance\"][\"score\"], reverse=True\n",
        "# )\n",
        "\n",
        "print(len(cluster_analysis))\n",
        "print(len(final_json_to_process))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "article_ids_used = []\n",
        "\n",
        "for el in final_json_to_process:\n",
        "    if \"keySources\" not in el:\n",
        "        print(\"No keySources\")\n",
        "        continue\n",
        "        \n",
        "    for source in el['keySources']['provided_articles_sources']:\n",
        "        for article_id in source['articles']:\n",
        "            article_ids_used.append(article_id)\n",
        "\n",
        "article_ids_used = list(set(article_ids_used))\n",
        "used_events = []\n",
        "used_sources = []\n",
        "for article_id in article_ids_used:\n",
        "    found_event = next((event for event in events if event.id == article_id), None)\n",
        "    if found_event:\n",
        "        link = found_event.url\n",
        "        # print(link)\n",
        "        \n",
        "        # get just domain name \n",
        "        domain = link.split(\"//\")[1].split(\"/\")[0]\n",
        "        if domain not in used_sources:\n",
        "            used_sources.append(domain)\n",
        "        \n",
        "        used_events.append(found_event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json # Assuming json is needed if loading from file elsewhere\n",
        "\n",
        "def json_to_markdown_refined(data):\n",
        "    \"\"\"\n",
        "    Converts refined JSON analysis data into structured markdown suitable \n",
        "    as input for a final briefing generation model.\n",
        "\n",
        "    Args:\n",
        "        data (dict): The JSON analysis data following the refined schema.\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted markdown string.\n",
        "    \"\"\"\n",
        "    if not data or data.get(\"status\") != \"complete\":\n",
        "        return \"# Analysis Incomplete\\n\\nReason: \" + data.get(\"reason\", \"Unknown\") + \"\\n\"\n",
        "\n",
        "    # --- Header ---\n",
        "    # Use Executive Summary as the core headline content\n",
        "    summary = data.get(\"executiveSummary\", \"No summary available.\")\n",
        "    status = data.get(\"storyStatus\", \"Status Unknown\")\n",
        "    markdown = f\"# Key Development Summary: {summary}\\n\"\n",
        "    markdown += f\"**(Story Status: {status})**\\n\\n\"\n",
        "\n",
        "    # --- Key Timeline Events (Prioritized) ---\n",
        "    if data.get(\"timeline\"):\n",
        "        markdown += \"## Key Timeline Events (High Importance)\\n\"\n",
        "        # Filter for 'High' importance events, limit to ~5 for brevity\n",
        "        high_importance_events = [\n",
        "            event for event in data[\"timeline\"] if event.get(\"importance\") == \"High\"\n",
        "        ]\n",
        "        # If few high importance, maybe include Medium? For now, just High.\n",
        "        limit = 5\n",
        "        for event in high_importance_events[:limit]:\n",
        "            markdown += f\"*   **{event.get('date', 'N/A')}:** {event.get('description', 'N/A')}\\n\"\n",
        "        if not high_importance_events:\n",
        "            markdown += \"*   *No high-importance events identified in timeline.*\\n\"\n",
        "        markdown += \"\\n\"\n",
        "\n",
        "    # --- Overall Significance ---\n",
        "    if data.get(\"significance\"):\n",
        "        markdown += \"## Overall Significance\\n\"\n",
        "        assessment = data[\"significance\"].get('assessment', 'N/A')\n",
        "        reasoning = data[\"significance\"].get('reasoning', 'No reasoning provided.')\n",
        "        markdown += f\"*   **Assessment:** {assessment}\\n\"\n",
        "        markdown += f\"*   **Reasoning:** {reasoning}\\n\\n\"\n",
        "\n",
        "    # --- Core Factual Basis ---\n",
        "    if data.get(\"undisputedKeyFacts\"):\n",
        "        markdown += \"## Core Factual Basis (Corroborated)\\n\"\n",
        "        limit = 5\n",
        "        for fact in data[\"undisputedKeyFacts\"][:limit]:\n",
        "            markdown += f\"*   {fact}\\n\"\n",
        "        if len(data[\"undisputedKeyFacts\"]) > limit:\n",
        "            markdown += f\"*   *(Additional facts available)*\\n\"\n",
        "        markdown += \"\\n\"\n",
        "        \n",
        "    # --- Key Contradictions / Contested Issues ---\n",
        "    if data.get(\"keySources\", {}).get(\"contradictions\"):\n",
        "        markdown += \"## Key Contradictions / Contested Issues\\n\"\n",
        "        limit = 3\n",
        "        contradictions = data[\"keySources\"][\"contradictions\"]\n",
        "        for contradiction in contradictions[:limit]:\n",
        "            issue = contradiction.get('issue', 'Unspecified Issue')\n",
        "            markdown += f\"*   **Issue:** {issue}\\n\"\n",
        "            # Optionally list the sources/claims briefly if needed, but issue might suffice\n",
        "            # for claim in contradiction.get('conflictingClaims', [])[:2]: # Show first 2 claims?\n",
        "            #    source = claim.get('source', 'Unknown Source')\n",
        "            #    claim_text = claim.get('claim', 'N/A')\n",
        "            #    markdown += f\"    *   {source}: Claims '{claim_text[:50]}...' \\n\" \n",
        "        if not contradictions:\n",
        "             markdown += \"*   *No major contradictions identified.*\\n\"\n",
        "        if len(contradictions) > limit:\n",
        "            markdown += f\"*   *(Additional contested issues identified)*\\n\"\n",
        "        markdown += \"\\n\"\n",
        "\n",
        "    # --- Key Entities Involved ---\n",
        "    if data.get(\"keyEntities\", {}).get(\"list\"):\n",
        "        markdown += \"## Key Entities Involved\\n\"\n",
        "        limit = 4\n",
        "        for entity in data[\"keyEntities\"][\"list\"][:limit]:\n",
        "            markdown += f\"*   **{entity.get('name', 'N/A')} ({entity.get('type', 'N/A')}):** {entity.get('involvement', 'N/A')}\\n\"\n",
        "        if len(data[\"keyEntities\"][\"list\"]) > limit:\n",
        "            markdown += f\"*   *(Additional entities involved)*\\n\"\n",
        "        markdown += \"\\n\"\n",
        "\n",
        "    # --- Critical Information Gaps ---\n",
        "    if data.get(\"informationGaps\"):\n",
        "        markdown += \"## Critical Information Gaps\\n\"\n",
        "        limit = 4\n",
        "        for gap in data[\"informationGaps\"][:limit]:\n",
        "            markdown += f\"*   {gap}\\n\"\n",
        "        if len(data[\"informationGaps\"]) > limit:\n",
        "            markdown += f\"*   *(Additional gaps identified)*\\n\"\n",
        "        markdown += \"\\n\"\n",
        "\n",
        "    # --- Assessment Summary (Signal & Reliability) ---\n",
        "    markdown += \"## Assessment Summary\\n\"\n",
        "    if data.get(\"signalStrength\"):\n",
        "        assessment = data[\"signalStrength\"].get('assessment', 'N/A')\n",
        "        reasoning = data[\"signalStrength\"].get('reasoning', 'No reasoning provided.')\n",
        "        markdown += f\"*   **Signal Strength:** {assessment}\\n\"\n",
        "        # Summarize reasoning briefly if desired, or rely on the assessment\n",
        "        # markdown += f\"*   **Basis:** {reasoning[:150]}...\\n\" \n",
        "    else:\n",
        "        markdown += \"*   Signal Strength: Not Assessed\\n\"\n",
        "        \n",
        "    # Add a note about source reliability variance\n",
        "    markdown += \"*   **Note:** Analysis based on sources of varying reliability (see full JSON for details). Claims from low-reliability sources require caution.\\n\"\n",
        "\n",
        "    return markdown\n",
        "\n",
        "# Example Usage (assuming 'refined_output_d' holds Model D's refined JSON output)\n",
        "# markdown_output = json_to_markdown_refined(refined_output_d) \n",
        "# print(markdown_output) \n",
        "\n",
        "stories_markdown = \"\"\n",
        "for i in range(len(final_json_to_process)):\n",
        "    cluster = final_json_to_process[i]\n",
        "    stories_markdown += \"\\n---\\n\\n\"+ json_to_markdown_refined(cluster)\n",
        "stories_markdown = stories_markdown[4:].strip()\n",
        "print(stories_markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final brief prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# with headers\n",
        "latest_report = requests.get(\n",
        "        \"https://meridian-production.alceos.workers.dev/last-report\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {os.environ.get('MERIDIAN_SECRET_KEY')}\"\n",
        "        }\n",
        "    )\n",
        "latest_report = latest_report.json()\n",
        "latest_report = f\"\"\"\n",
        "## Previous Day's Coverage Context ({latest_report['createdAt'].split('T')[0]})\n",
        "\n",
        "### {latest_report['title']}\n",
        "\n",
        "{latest_report['tldr']}\n",
        "\"\"\"\n",
        "print(latest_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_brief_prompt(curated_news: str):\n",
        "    prompt = f\"\"\"\n",
        "hey, i have a bunch of news reports (in random order) derived from detailed analyses of news clusters from the last 30h. could you give me my personalized daily intelligence brief? aim for something comprehensive yet engaging, roughly a 20-30 minute read.\n",
        "\n",
        "my interests are: significant world news (geopolitics, politics, finance, economics), us news, france news (i'm french/live in france), china news (especially policy, economy, tech - seeking insights often missed in western media), and technology/science (ai/llms, biomed, space, real breakthroughs). also include a section for noteworthy items that don't fit neatly elsewhere.\n",
        "\n",
        "some context: i built a system that collects/analyzes/compiles news because i was tired of mainstream news that either overwhelms with useless info or misses what actually matters. you're really good at information analysis/writing/etc so i figure by just asking you this i'd get something even better than what presidents get - a focused brief that tells me what's happening, why it matters, and what connections exist that others miss. i value **informed, analytical takes**  even if i don't agree with them, they're intellectually stimulating. i want analysis grounded in the facts provided, free from generic hedging or forced political correctness.\n",
        "\n",
        "your job: go through all the curated news data i've gathered below. analyze **everything** first to identify what *actually* matters before writing. look for:\n",
        "- actual significance (not just noise/volume)\n",
        "- hidden patterns and connections between stories\n",
        "- important developments flying under the radar\n",
        "- how separate events might be related\n",
        "- genuinely interesting or impactful stories\n",
        "\n",
        "**--- CONTEXT FROM PREVIOUS DAY (IF AVAILABLE) ---**\n",
        "*   You *may* receive a section at the beginning of the curated data titled `## Previous Day's Coverage Context (YYYY-MM-DD)`.\n",
        "*   This section provides a highly condensed list of major stories covered yesterday, using the format: `[Story Identifier] | [Last Status] | [Key Entities] | [Core Issue Snippet]`.\n",
        "*   **How to Use This Context:** Use this list **only** to understand which topics are ongoing and their last known status/theme. This helps ensure continuity and avoid repeating information already covered.\n",
        "*   **Focus on Today:** Your primary task is to synthesize and analyze **today's developments** based on the main `<curated_news_data>`. When discussing a story listed in the previous context, focus on **what is new or has changed today**. Briefly reference the past context *only if essential* for understanding the update (e.g., \"Following yesterday's agreement...\", \"The situation escalated further today when...\").\n",
        "*   **Do NOT simply rewrite or extensively quote the Previous Day's Coverage Context.** Treat it as background memory.\n",
        "**--- END CONTEXT INSTRUCTIONS ---**\n",
        "\n",
        "here's the curated data (each section represents an analyzed news cluster; you might need to synthesize across sections):\n",
        "\n",
        "{latest_report}\n",
        "\n",
        "<curated_news_data>\n",
        "\n",
        "{curated_news}\n",
        "\n",
        "</curated_news_data>\n",
        "\n",
        "structure the brief using the sections below, making it feel conversational  complete sentences, natural flow, occasional wry commentary where appropriate.\n",
        "<final_brief>\n",
        "## what matters now\n",
        "cover the *up to* 7-8 most significant stories with real insight. for each:\n",
        "<u>**title that captures the essence**</u>\n",
        "weave together what happened, why it matters (significance, implications), key context, and your analytical take in natural, flowing paragraphs.\n",
        "separate paragraphs with linebreaks for readability, but ensure smooth transitions.\n",
        "blend facts and analysis naturally. **if there isn't much significant development or analysis for a story, keep it brief  don't force length.** prioritize depth and insight where warranted.\n",
        "use **bold** for key specifics (names, places, numbers, orgs), *italics* for important context or secondary details.\n",
        "offer your **analytical take**: based on the provided facts and context, what are the likely motivations, potential second-order effects, overlooked angles, or inconsistencies? ground this analysis in the data.\n",
        "\n",
        "## france focus\n",
        "(i'm french/live in france)\n",
        "significant french developments: policy details, key players, economic data, political shifts.\n",
        "\n",
        "## global landscape\n",
        "### power & politics\n",
        "key geopolitical moves, focusing on outcomes and strategic implications, including subtle shifts.\n",
        "\n",
        "### china monitor\n",
        "(seeking insights often missed in western media - skip if nothing significant)\n",
        "meaningful policy shifts, leadership dynamics, economic indicators (with numbers if available), tech developments, social trends.\n",
        "\n",
        "### economic currents\n",
        "market movements signaling underlying trends, impactful policy decisions, trade/resource developments (with data), potential economic risks or opportunities.\n",
        "\n",
        "## tech & science developments\n",
        "(focus on ai/llms, space, biomed, real breakthroughs - skip if only minor product news)\n",
        "actual breakthroughs, notable ai/llm advancements, significant space news, key scientific progress. separate signal from noise.\n",
        "\n",
        "## noteworthy & under-reported\n",
        "(combine under-reported significance and carte blanche)\n",
        "important stories flying under the radar, emerging patterns with specific indicators, slow-burning developments, or other interesting items you think i should see (up to 5 items max).\n",
        "\n",
        "## positive developments\n",
        "(skip if nothing genuinely positive/significant, don't force it)\n",
        "actual progress with measurable outcomes, effective solutions, verifiable improvements.\n",
        "</final_brief>\n",
        "\n",
        "use the:\n",
        "```\n",
        "<u>**title that captures the essence**</u>\n",
        "paragraph\n",
        "\n",
        "paragraph\n",
        "\n",
        "...\n",
        "```\n",
        "for all sections.\n",
        "\n",
        "make sure everything inside the <final_brief></final_brief> tags is the actual brief content itself. any/all \"hey, here is the brief\" or \"hope you enjoyed today's brief\" should either not be included or be before/after the <final_brief></final_brief> tags.\n",
        "\n",
        "**final instructions:**\n",
        "*   always enclose the brief inside <final_brief></final_brief> tags.\n",
        "*   use lowercase by default like i do. complete sentences please.\n",
        "*   this is for my eyes only - be direct and analytical.\n",
        "*   **source reliability:** the input data is derived from analyses that assessed source reliability. use this implicit understanding  give more weight to information from reliable sources and treat claims originating solely from known low-reliability/propaganda sources with appropriate caution in your analysis and 'take'. explicitly mentioning source reliability isn't necessary unless a major contradiction hinges on it.\n",
        "*   **writing style:** aim for the tone of an extremely well-informed, analytical friend with a dry wit and access to incredible information processing. be insightful, engaging, and respect my time. make complex topics clear without oversimplifying. integrate facts, significance, and your take naturally.\n",
        "*   **leverage your strengths:** process all the info, spot cross-domain patterns, draw on relevant background knowledge (history, economics, etc.), explain clearly, and provide that grounded-yet-insightful analytical layer.\n",
        "\n",
        "give me the brief i couldn't get before ai - one that combines human-like insight with superhuman information processing.\n",
        "\"\"\".strip()\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# curated_news_data = \"\"\n",
        "# for el in ok_now_were_good:\n",
        "#     curated_news_data += el.text\n",
        "#     curated_news_data += \"\\n\\n---\\n\\n\"\n",
        "# curated_news_data = curated_news_data.strip()\n",
        "# if curated_news_data.endswith(\"---\"):\n",
        "#     curated_news_data = curated_news_data[:-4]\n",
        "# curated_news_data = curated_news_data.strip()\n",
        "\n",
        "systemPrompt = \"\"\"\n",
        "Adopt the persona of an exceptionally well-informed, highly analytical, and slightly irreverent intelligence briefer. Imagine you have near-instant access to and processing power for vast amounts of global information, combined with a sharp, insightful perspective and a dry wit. You're communicating directly and informally with a smart, curious individual who values grounded analysis but dislikes corporate speak, hedging, and forced neutrality.\n",
        "\n",
        "**Your core stylistic goals are:**\n",
        "\n",
        "1.  **Tone:** Conversational, direct, and engaging. Use lowercase naturally, as if speaking or writing informally to a trusted peer. Avoid stiff formality, bureaucratic language, or excessive caution. Be chill, but maintain intellectual rigor.\n",
        "2.  **Analytical Voice:** Prioritize insightful analysis over mere summarization. Go beyond stating facts to explain *why* they matter, connect disparate events, identify underlying patterns, assess motivations, and explore potential implications (second-order effects). Offer a clear, grounded \"take\" on developments. Don't be afraid to call out inconsistencies or highlight underappreciated angles, always backing it up with the logic derived from the provided information.\n",
        "3.  **Wit & Personality:** Embrace a dry, clever wit. Humor, sarcasm, or irony should arise *naturally* from the situation or the absurdity of events. Pointing out the obvious when it's funny is fine. **Crucially: Do not force humor, be cringe, or undermine the gravity of serious topics like human suffering.** Wit should enhance insight, not detract from it.\n",
        "4.  **Language:** Use clear, concise language. Vary sentence structure for natural flow. Occasional relevant slang or shorthand is acceptable if it fits the informal tone naturally, but prioritize clarity. Ensure analysis is sharp and commentary is insightful, not just filler.\n",
        "\n",
        "**Think of yourself as:** The user's personal \"Q\" (from James Bond) combined with a sharp geopolitical analyst  someone with unparalleled information access who can cut through the noise, connect the dots, and deliver the essential insights with a bit of personality and zero tolerance for BS.\n",
        "\n",
        "**Relationship to Main Prompt:** This system prompt defines *how* you should wrte and analyze. Follow the specific content structure, formatting, and topic instructions provided in the main user prompt separately. Your analysis and 'take' should always be grounded in the information provided in the main prompt's `<curated_news_data>` section.\n",
        "\n",
        "Your ultimate goal is to deliver the kind of insightful, personalized, and engaging intelligence brief that wasn't possible before AI  combining superhuman data processing with a distinct, analytical, and trustworthy (even if slightly cynical) voice.\n",
        "\"\"\".strip()\n",
        "\n",
        "brief_prompt = get_brief_prompt(stories_markdown)\n",
        "brief_model = \"gemini-2.5-pro-exp-03-25\"\n",
        "# print(brief_prompt)\n",
        "brief_response = call_llm(\n",
        "    model=brief_model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": systemPrompt},\n",
        "        {\"role\": \"user\", \"content\": brief_prompt},\n",
        "    ],\n",
        "    temperature=0.7,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.genai.types import FinishReason\n",
        "\n",
        "\n",
        "final_brief_text = brief_response[0]\n",
        "assert \"<final_brief>\" in final_brief_text\n",
        "final_brief_text = final_brief_text.split(\"<final_brief>\")[1]\n",
        "\n",
        "assert \"</final_brief>\" in final_brief_text\n",
        "final_brief_text = final_brief_text.split(\"</final_brief>\")[0]\n",
        "\n",
        "final_brief_text = final_brief_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import base64\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "client = genai.Client(\n",
        "    api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
        ")\n",
        "\n",
        "\n",
        "brief_title_prompt = f\"\"\"\n",
        "<brief>\n",
        "{final_brief_text}\n",
        "</brief>\n",
        "\n",
        "create a title for the brief. construct it using the main topics. it should be short/punchy/not clickbaity etc. make sure to not use \"short text: longer text here for some reason\" i HATE it, under no circumstance should there be colons in the title. make sure it's not too vague/generic either bc there might be many stories. maybe don't focus on like restituting what happened in the title, just do like the major entities/actors/things that happened. like \"[person A], [thing 1], [org B] & [person O]\" etc. try not to use verbs. state topics instead of stating topics + adding \"shakes world order\". always use lowercase.\n",
        "\n",
        "return exclusively a JSON object with the following format:\n",
        "```json\n",
        "{{\n",
        "    \"title\": \"string\"\n",
        "}}\n",
        "```\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "brief_title_response = call_llm(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": brief_title_prompt}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "brief_title = brief_title_response[0]\n",
        "if brief_title.startswith(\"```json\"):\n",
        "    brief_title = brief_title.split(\"```json\")[1]\n",
        "if brief_title.endswith(\"```\"):\n",
        "    brief_title = brief_title.split(\"```\")[0]\n",
        "brief_title = brief_title.strip()\n",
        "brief_title = json.loads(brief_title)['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "tldr_prompt = f\"\"\"\n",
        "\n",
        "You are an information processing agent tasked with creating a highly condensed 'memory state' or 'context brief' from a detailed intelligence briefing. Your output will be used by another AI model tomorrow to understand what topics were covered today, ensuring continuity without requiring it to re-read the full brief.\n",
        "\n",
        "**Your Task:**\n",
        "\n",
        "Read the full intelligence brief provided below within the `<final_brief>` tags. Identify each distinct major story or narrative thread discussed. For **each** identified story, extract the necessary information and format it precisely according to the specified structure.\n",
        "\n",
        "**Input:**\n",
        "\n",
        "The input is the full text of the daily intelligence brief generated previously.\n",
        "\n",
        "<final_brief>\n",
        "# {brief_title}\n",
        "\n",
        "{final_brief_text}\n",
        "</final_brief>\n",
        "\n",
        "**Required Output Format:**\n",
        "\n",
        "Your entire output must consist **only** of a list of strings, one string per identified story, following this exact format:\n",
        "\n",
        "`[Story Identifier] | [Inferred Status] | [Key Entities] | [Core Issue Snippet]`\n",
        "\n",
        "**Explanation of Output Components:**\n",
        "\n",
        "1.  **`[Story Identifier]`:** Create a concise, descriptive label for the story thread (max 4-5 words). Examples: `US-Venezuela: Deportations`, `Gaza: Ceasefire Collapse`, `UK: Economy Update`, `AI: Energy Consumption`. Use keywords representing the main actors and topic.\n",
        "2.  **`[Inferred Status]`:** Based *only* on the tone and content of the discussion *within the provided brief*, infer the story's current state. Use one of: `New`, `Developing`, `Escalating`, `De-escalating`, `Resolved`, `Ongoing`, `Static`.\n",
        "3.  **`[Key Entities]`:** List the 3-5 most central entities (people, organizations, countries) mentioned *in the context of this specific story* within the brief. Use comma-separated names. Example: `Trump, Maduro, US, Venezuela, El Salvador`.\n",
        "4.  **`[Core Issue Snippet]`:** Summarize the absolute essence of *this story's main point or development as covered in the brief* in **5-10 words maximum**. This requires extreme conciseness. Example: `Deportations resume via Honduras amid legal challenges`, `Ceasefire over, hospital strike, offensive planned`, `Talks falter, missile strike during meeting`.\n",
        "\n",
        "**Instructions & Constraints:**\n",
        "\n",
        "*   **Process Entire Brief:** Read and analyze the *whole* brief to identify all distinct major stories. Stories under `<u>**title**</u>` headings are primary candidates, but also consider distinct, significant themes from other sections (e.g., a recurring topic in 'Global Landscape').\n",
        "*   **One Line Per Story:** Each identified story must correspond to exactly one line in the output, following the specified format.\n",
        "*   **Strict Conciseness:** Adhere strictly to the format and the word limit for the `[Core Issue Snippet]`. This is critical.\n",
        "*   **Focus on Coverage:** The goal is to capture *what was discussed*, not the full nuance or analysis.\n",
        "*   **Inference for Status:** You must *infer* the status based on the brief's content, as it's not explicitly stated per story in the input brief text.\n",
        "*   **No Extra Text:** Do **NOT** include any headers, explanations, introductions, or conclusions in your output. Output *only* the list of formatted strings.\n",
        "\n",
        "Generate the condensed context brief based *only* on the provided `<final_brief>` text.\n",
        "\"\"\".strip()\n",
        "\n",
        "tldr_response = call_llm(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": tldr_prompt}\n",
        "    ],\n",
        "    temperature=0.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tldr = tldr_response[0]\n",
        "if tldr.startswith(\"```\"):\n",
        "    tldr = tldr.split(\"```\")[1]\n",
        "if tldr.endswith(\"```\"):\n",
        "    tldr = tldr.split(\"```\")[0]\n",
        "tldr = tldr.strip()\n",
        "print(tldr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Publish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"========== STATS ==========\")\n",
        "print(f\"Total articles: {len(events)}\")\n",
        "print(f\"Total sources: {len(sources)}\")\n",
        "print(f\"Total used articles: {len(used_events)}\")\n",
        "print(f\"Total used sources: {len(used_sources)}\")\n",
        "print(f\"Model used: {brief_model}\")\n",
        "print(\"========== STATS ==========\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"# {brief_title}\\n\")\n",
        "print(final_brief_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import requests\n",
        "\n",
        "body = {\n",
        "    \"title\": brief_title,\n",
        "    \"content\": final_brief_text,\n",
        "    \"totalArticles\": len(events),\n",
        "    \"totalSources\": len(sources),\n",
        "    \"usedArticles\": len(used_events),\n",
        "    \"usedSources\": len(used_sources),\n",
        "    \"tldr\": tldr,\n",
        "    \"model_author\": brief_model,\n",
        "    \"createdAt\": datetime.now().isoformat(),\n",
        "    \"clustering_params\": best_params,\n",
        "}\n",
        "\n",
        "endpoint = \"https://meridian-production.alceos.workers.dev/report\"\n",
        "\n",
        "response = requests.post(\n",
        "    endpoint,\n",
        "    json=body,\n",
        "    headers={\"Authorization\": f\"Bearer {os.environ.get('MERIDIAN_SECRET_KEY')}\"},\n",
        ")\n",
        "print(response.json())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
